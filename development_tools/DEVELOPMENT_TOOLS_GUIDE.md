# Development Tools Guide

> **File**: `development_tools/DEVELOPMENT_TOOLS_GUIDE.md`
> **Audience**: Human maintainers and contributors
> **Purpose**: Detailed reference for every development tool, its tiers, trust level, and scope
> **Style**: Explicit, actionable, high-signal
> **Pair**: [AI_DEVELOPMENT_TOOLS_GUIDE.md](development_tools/AI_DEVELOPMENT_TOOLS_GUIDE.md)
> This document is paired with [AI_DEVELOPMENT_TOOLS_GUIDE.md](development_tools/AI_DEVELOPMENT_TOOLS_GUIDE.md). Keep both H2 headings identical and keep the AI doc concise while this guide carries the detailed context.

---

## 1. Purpose and Scope

Use this guide when you need:
- The authoritative human-readable catalog of tools and tiers
- Rationale behind trust levels and roadmap priorities
- Links to supporting plans such as [AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md](development_tools/AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md)

The machine-readable metadata lives in `development_tools/shared/tool_metadata.py` and is surfaced to AI collaborators through the paired guide.

**Note on Tool Relationships**: These development tools are complementary to other quality tools (Pyright for type checking, ruff/bandit for security/style). They focus on project-specific analysis (error handling patterns, documentation sync, legacy reference tracking) that no existing tools provide. See [TODO.md](TODO.md) for evaluation tasks for complementary tools.

---

## 2. Running the Tool Suite

All commands flow through `development_tools/run_development_tools.py` (or the shorter alias `development_tools/run_dev_tools.py`).

### 2.1. Global Options

The runner supports global options that apply to all commands:

```powershell
# Specify a custom project root
python development_tools/run_development_tools.py --project-root /path/to/project status
# Or use the shorthand:
python development_tools/run_dev_tools.py --project-root /path/to/project status

# Specify a custom config file
python development_tools/run_development_tools.py --config-path /path/to/config.json audit

# Combine both
python development_tools/run_development_tools.py --project-root . --config-path development_tools/config/development_tools_config.json status
```

**Configuration File**: By default, the tools look for `development_tools/config/development_tools_config.json`. This file can override paths, project settings, audit behavior, and other configuration. See `development_tools/development_tools_config.json.example` for a template.

### 2.2. Command Examples

```powershell
python development_tools/run_development_tools.py --help
python development_tools/run_development_tools.py audit
python development_tools/run_development_tools.py audit --full
python development_tools/run_development_tools.py docs
python development_tools/run_development_tools.py doc-fix --full
python development_tools/run_development_tools.py status
python development_tools/run_development_tools.py legacy
python development_tools/run_development_tools.py coverage
python development_tools/run_development_tools.py unused-imports
python development_tools/run_development_tools.py unused-imports-report
python development_tools/run_development_tools.py config
```

### 2.3. Command Summary

**Core Commands** (daily-safe, audit-first workflow):
- `audit` - Standard audit (Tier 2, default); regenerates quality checks and cached signals.
- `audit --quick` - Quick audit (Tier 1); core metrics only (~30-60s).
- `audit --full` - Full audit (Tier 3); comprehensive analysis including coverage (~10-30min, alias: full-audit).
- `docs` - regenerates registries, dependency maps, and doc-signals.
- `doc-sync` - verifies paired doc headings, path drift, ASCII compliance.
- `doc-fix` - fixes documentation issues (addresses, ASCII, headings, links). Alias: `--full` == `--all`.
- `config` - prints configuration validation report with tool analysis and recommendations.
- `coverage` - invokes `development_tools/tests/run_test_coverage.py` (executes tests, generates coverage data). Reports (TEST_COVERAGE_REPORT.md, HTML, JSON) are generated by `development_tools/tests/generate_test_coverage_report.py`.
- `legacy` - runs `development_tools/legacy/fix_legacy_references.py` via the dispatcher.

**Supporting Commands** (advisory, depend on fresh audits):
- `status` - surfaces cached health summaries (rerun `audit` if stale).
- `system-signals` - generates system health and status signals.
- `validate` - validates AI-generated work (lightweight structural validation).
- `decision-support` - generates decision support insights.
- `unused-imports` - runs the AST-based unused import detection tool (analysis only).
- `unused-imports-report` - generates unused imports report from analysis results.
- `duplicate-functions` - detects possible duplicate or similar functions (analysis only).
- `workflow` - executes an audit-first workflow task.
- `export-code` - Exports Python source files from a specified directory into a single Markdown snapshot for LLM context (portable, project-root-relative paths).
- `trees` - generates directory tree reports.
- `cleanup` - cleans up project cache files, temporary directories, and artifacts. (alias: clean-up)
- `help` - shows detailed help information.

**Experimental Commands** (high-risk, run only with approval):
- `version-sync` - synchronizes version metadata across files (fragile, use with caution).

### 2.4. Entry Point Expectations

Regardless of command:
- Respect shared configuration from `development_tools/config/config.py` (with external config file support via `development_tools/config/development_tools_config.json`).
- Honor universal exclusions defined in `shared/standard_exclusions.py`.
- Avoid importing business logic modules (operate via filesystem + configs only).
- Route logging through the `development_tools` component logger.
- Emit ASCII output to stay Windows-safe.

**Configuration Priority**:
1. External config file (`development_tools/config/development_tools_config.json`, or path specified via `--config-path`)
2. Hardcoded defaults in `development_tools/config/config.py` (generic/empty fallbacks for portability)
3. Environment-specific detection (project root, scan directories, etc.)

**Portability**: All tools are portable and can be used in other projects. Create a `development_tools/config/development_tools_config.json` file (see `development_tools/development_tools_config.json.example` for a template) to customize paths, exclusions, constants, and other project-specific settings.

### 2.5. Service Architecture

The development tools suite uses a modular service architecture. The main `AIToolsService` class is composed from mixin classes located in `development_tools/shared/service/`:

- **`development_tools/shared/service/core.py`**: Base `AIToolsService` class with initialization and configuration
- **`development_tools/shared/service/utilities.py`**: `UtilitiesMixin` - Formatting and extraction utility methods
- **`development_tools/shared/service/data_loading.py`**: `DataLoadingMixin` - Data loading and parsing methods
- **`development_tools/shared/service/tool_wrappers.py`**: `ToolWrappersMixin` - Tool execution wrappers and `SCRIPT_REGISTRY`
- **`development_tools/shared/service/audit_orchestration.py`**: `AuditOrchestrationMixin` - Audit workflow and tier management
- **`development_tools/shared/service/report_generation.py`**: `ReportGenerationMixin` - Report generation methods
- **`development_tools/shared/service/commands.py`**: `CommandsMixin` - Command execution methods

The CLI interface (`COMMAND_REGISTRY` and command handlers) is in `development_tools/shared/cli_interface.py`. For new code, import `AIToolsService` from `development_tools.shared.service` and `COMMAND_REGISTRY` from `development_tools.shared.cli_interface`:

```python
from development_tools.shared.service import AIToolsService
from development_tools.shared.cli_interface import COMMAND_REGISTRY
```

The modular structure provides clear separation of concerns, making the codebase more maintainable and testable. Each module has a single responsibility and can be tested independently.

---

## 3. Audit Modes and Outputs

**Tier 1: Quick Audit (`audit --quick`)** collects all tools <=2s execution time:
- **Core metrics**: System health, quick status
- **Quick checks**: Documentation analysis, config validation, AI work validation
- **Module imports**: Module import extraction, dependency patterns
- **Function analysis**: Function patterns, decision support, function registry validation
- **Duration**: ~5-10 seconds (with parallel execution)

**Tier 2: Standard Audit (`audit`, default)** includes all tools >2s but <=10s execution time:
- **Function discovery**: Function discovery and complexity metrics (required by dependent tools)
- **Quality checks**: Error handling coverage, package export validation
- **Documentation sync**: Documentation synchronization (includes multiple sub-tools)
- **Module dependencies**: Module dependency validation (depends on module imports from Tier 1)
- **Unused imports**: Unused import detection and report generation
- **Duration**: ~15-25 seconds (with parallel execution)

**Tier 3: Full Audit (`audit --full`)** includes everything in Tier 1 & 2 plus tools >10s (or groups containing tools >10s):
- **Coverage tools** (run in parallel, ~365s max):
- Full pytest execution with coverage regeneration (~365s, >10s)
- Dev tools test coverage (~94s, >10s, runs in parallel with main tests)
- **Coverage-dependent tools** (run sequentially after coverage completes, ~7s):
- Test marker analysis (~2s, requires coverage data from both test suites)
- Coverage report generation (~5s, requires coverage data from both test suites)
- **Legacy group** (runs in parallel with coverage tools):
- Legacy reference scanning (~62s, >10s)
- Reference report generation (~1s, but part of the legacy reference group)
- Improvement opportunity reports (LEGACY_REFERENCE_REPORT.md, TEST_COVERAGE_REPORT.md, UNUSED_IMPORTS_REPORT.md)

**Performance**: Total full audit time: ~6-7 minutes (coverage tools run in parallel, reducing total time from ~460s to ~365s)

Pipeline artifacts:
- AI-facing (root): [AI_STATUS.md](development_tools/AI_STATUS.md), `AI_PRIORITIES.md`, `consolidated_report.txt`
- Domain-specific JSON: `reports/analysis_detailed_results.json`, `error_handling/error_handling_details.json`, `tests/jsons/coverage_dev_tools.json`, `config/analyze_config_results.json`, `imports/.unused_imports_cache.json`
- `reports/analysis_detailed_results.json` caches complexity metrics, validation results, and system signals for `status` command
- `AI_PRIORITIES.md` includes complexity refactoring priority when critical/high complexity functions exist

**Report Format Standards**:
- **AI_STATUS.md**: High-level summary including Function Docstring Coverage (with missing count) and Registry Gaps (separate metrics)
- **AI_PRIORITIES.md**: Actionable priorities with prioritized example lists (functions and handler classes) using ",... +N" format when there are more items
- **consolidated_report.txt**: Comprehensive details including all metrics from AI_STATUS plus detailed example lists in the Function Patterns section
- Human-facing: [FUNCTION_REGISTRY_DETAIL.md](development_docs/FUNCTION_REGISTRY_DETAIL.md), [MODULE_DEPENDENCIES_DETAIL.md](development_docs/MODULE_DEPENDENCIES_DETAIL.md), [LEGACY_REFERENCE_REPORT.md](development_docs/LEGACY_REFERENCE_REPORT.md), [UNUSED_IMPORTS_REPORT.md](development_docs/UNUSED_IMPORTS_REPORT.md)
- Coverage: `development_tools/tests/jsons/coverage.json`, `development_tools/tests/jsons/coverage_dev_tools.json`, `development_tools/tests/coverage_html/`, `development_tools/reports/archive/coverage_artifacts/<timestamp>/`
- Cached snapshots: `status` loads data from `reports/analysis_detailed_results.json` (complexity, validation, system signals); confirm timestamps before trusting

**Tool Output Format**:
- All analysis tools that participate in audit aggregation output JSON in a standardized structure for consistent data aggregation:
```json
{
"summary": {
"total_issues": <number>,
"files_affected": <number>,
"status": "<PASS|FAIL|WARN>" (optional)
},
"details": {
// Tool-specific data (original metrics, findings, etc.)
}
}
```
- Tools support `--json` flag to output standard format directly when run standalone
- Tool results must already be in standard format; validation is strict
- Report generation code accesses data from `details` section
- This standardization enables consistent data aggregation, easier tool integration, and simplified report generation.

**When to run each command**: See "Standard Audit Recipe" section in [AI_DEVELOPMENT_WORKFLOW.md](ai_development_docs/AI_DEVELOPMENT_WORKFLOW.md) for guidance on day-to-day checks (`audit`), pre-merge/pre-release checks (`audit --full`), and documentation work (`doc-sync`, `docs`).

Ensure directories listed in `development_tools/shared/constants.py` remain accurate so reports resolve predictably.

---

## 4. Tool Catalog and Tiering

### 4.1. Naming Conventions

Most tools follow a 3-prefix naming system established in :

- **`analyze_*`** - Finding + assessing (read-only examination, validation, detection)
- Examples: `analyze_functions.py`, `analyze_documentation.py`, `analyze_error_handling.py`, `tests/analyze_test_coverage.py`
- These tools examine code/documentation and report findings without modifying anything
- **`generate_*`** - Making artifacts (create/recreate documentation, registries, reports)
- Examples: `generate_function_registry.py`, `tests/run_test_coverage.py`, `generate_module_dependencies.py`
- These tools create or regenerate documentation and report files
- **`fix_*`** - Cleanup/repair (removal, cleanup operations)
- Examples: `fix_legacy_references.py`, `fix_version_sync.py`, `fix_project_cleanup.py` (legacy reference cleanup tool included)
- These tools perform cleanup, removal, or repair operations (often support `--dry-run`)
- **No prefix** - Reporting/utility tools (descriptive names)
- Examples: `decision_support.py`, `quick_status.py`, `system_signals.py`, `file_rotation.py`, `tool_guide.py`
- These are utility or reporting tools that don't fit the analyze/generate/fix pattern

Tools under `development_tools/shared/` (service orchestration, registries, normalization, storage, and other infrastructure) may not fit cleanly into a single prefix category. Prefixes indicate primary intent, not a strict contract.

Tools are organized by domain (functions/, docs/, tests/, etc.) and follow these naming conventions consistently. This makes it easy to understand a tool's purpose at a glance.

### 4.2. Tier overview

| Tier | Trust Level | Description |
| --- | --- | --- |
| Core | stable | Safe for daily runs; required for audit-first workflow. |
| Supporting | partial / advisory | Helpful but dependent on fresh audit data; verify results manually. |
| Experimental | experimental | Prototype/high-risk commands; run only with explicit approval and backups. |

### 4.3. Detailed catalog

| Tool | Tier | Trust | Notes |
| --- | --- | --- | --- |
| run_development_tools.py | core | stable | CLI dispatcher for every development tooling command. Supports `--project-root` and `--config-path` for portability. |
| shared/cli_interface.py | core | stable | Implements command handlers and COMMAND_REGISTRY for CLI interface. |
| shared/service/ | core | stable | Modular service architecture with AIToolsService composed from mixin classes. Accepts project-specific config via external config file. |
| config/config.py | core | stable | Central configuration for audit contexts, paths, and workflow knobs. Loads from `development_tools/config/development_tools_config.json` with generic fallbacks. |
| shared/standard_exclusions.py | core | stable | Canonical exclusion patterns consumed by all scanners. Loads exclusions from external config. |
| shared/constants.py | core | stable | Doc pairing metadata, directory maps, and shared enumerations. Loads constants from external config. |
| shared/common.py | core | stable | IO helpers plus CLI utilities (command grouping, runners). |
| analyze_documentation_sync.py | core | stable | Validates paired documentation (human vs AI) and detects heading sync issues. Parameterized doc roots and metadata schema. 
| docs/analyze_path_drift.py | core | stable | Analyzes path drift between codebase and documentation. |
| docs/analyze_ascii_compliance.py | core | stable | Checks ASCII compliance in documentation files. |
| docs/analyze_heading_numbering.py | core | stable | Validates H2 and H3 heading numbering in documentation. |
| docs/analyze_missing_addresses.py | core | stable | Detects missing file addresses in documentation files. |
| docs/analyze_unconverted_links.py | core | stable | Detects unconverted file path references in documentation. |
| docs/generate_directory_tree.py | core | stable | Generates directory tree reports for documentation. |
| docs/fix_documentation.py | core | stable | Dispatcher that orchestrates all documentation fix operations.
| docs/fix_documentation_addresses.py | core | stable | Adds file addresses to documentation files that don't have them. |
| docs/fix_documentation_ascii.py | core | stable | Fixes non-ASCII characters in documentation files. |
| docs/fix_documentation_headings.py | core | stable | Numbers H2 and H3 headings in documentation files. |
| docs/fix_documentation_links.py | core | stable | Converts file path references to markdown links in documentation. |
| imports/generate_module_dependencies.py | core | stable | Orchestrates module dependency analysis and generates dependency documentation. Accepts custom module prefixes for portability. 
| imports/analyze_module_imports.py | core | stable | Extracts and analyzes imports from Python files. Provides import parsing, scanning, reverse dependencies, dependency changes, purpose inference, and import formatting. |
| imports/analyze_dependency_patterns.py | core | stable | Analyzes dependency patterns, circular dependencies, and risk areas. Provides pattern analysis, circular dependency detection, risk area detection, and critical dependency finding. |
| legacy/fix_legacy_references.py | core | stable | Finds/validates legacy markers before cleanup. Pattern mappings load from external config. 
| tests/run_test_coverage.py | core | stable | Orchestrates coverage execution (pytest runs) and artifact management. Executes tests and collects coverage data. Accepts pytest command, coverage config, and artifact directories via external config. 
| tests/analyze_test_coverage.py | core | stable | Parses coverage output and performs coverage analysis. Pure analysis tool that works with existing coverage data. Includes caching support - caches analysis results based on coverage JSON file mtime. |
| tests/generate_test_coverage_report.py | core | stable | Generates coverage reports (TEST_COVERAGE_REPORT.md, JSON, HTML) from analysis results. Uses TestCoverageReportGenerator class to create reports from coverage.json. |
| tests/domain_mapper.py | core | stable | Maps source code directories to test directories and pytest markers for test-file coverage caching. Provides `DomainMapper` class to identify which tests cover which source domains. Used by `tests/test_file_coverage_cache.py` for selective test execution. |
| tests/test_file_coverage_cache.py | core | stable | Test-file-based coverage cache. Tracks domain changes and selects test files to re-run, then merges cached and fresh coverage. Cache location: `development_tools/tests/jsons/test_file_coverage_cache.json`. |
| tests/dev_tools_coverage_cache.py | core | stable | Dev tools coverage cache for `development_tools` tests. Stores coverage JSON keyed by dev tools source mtimes. Cache location: `development_tools/tests/jsons/dev_tools_coverage_cache.json`. |
| analyze_error_handling.py | core | stable | Audits decorator usage and exception handling depth. Decorator names and exception classes load from external config. Generates recommendations internally as part of analysis. |
| generate_error_handling_report.py | supporting | stable | Generates error handling reports from analysis results. |
| analyze_functions.py | core | stable | AST discovery utility supporting registries and audits. Configurable scan roots and filters via external config. Enhanced with function/class discovery logic from generate_function_registry.py. |
| analyze_duplicate_functions.py | supporting | partial | Flags possible duplicate/similar functions and methods using weighted similarity scoring. |
| analyze_function_patterns.py | core | stable | Analyzes function patterns (handlers, managers, factories, etc.) for AI consumption. |
| generate_function_registry.py | core | stable | Builds the authoritative function registry via AST parsing. 
| analyze_documentation.py | supporting | partial | Secondary doc analysis that focuses on corruption/overlap. |
| analyze_function_registry.py | supporting | partial | Validates generated function registry output. |
| analyze_module_dependencies.py | supporting | partial | Cross-checks generated dependency graphs for accuracy. |
| analyze_package_exports.py | supporting | partial | Confirms package export declarations match filesystem reality. |
| analyze_config.py | supporting | partial | Detects configuration drift and missing values across tools. |
| analyze_ai_work.py | supporting | partial | Lightweight structural validator; advisory results only. |
| analyze_unused_imports.py | supporting | partial | AST-based unused import detector (analysis only, no report generation). |
| generate_unused_imports_report.py | supporting | partial | Generates markdown report from unused imports analysis results. |
| quick_status.py | supporting | advisory | Cached status snapshot that depends on the latest audit run. |
| system_signals.py | supporting | advisory | Collects OS/process health signals for consolidated reports. |
| decision_support.py | supporting | advisory | Aggregates metrics into improvement priorities. |
| shared/file_rotation.py | supporting | stable | Timestamped rotation utility used by coverage generation. |
| shared/export_code_snapshot.py | supporting | stable | Exports Python source files into a single Markdown snapshot for LLM context. |
| shared/tool_guide.py | supporting | stable | Provides contextual guidance and tier overviews for assistants. |
| docs/fix_version_sync.py | experimental | experimental | Attempts cross-file version synchronization (fragile). |
| functions/generate_function_docstrings.py | experimental | experimental | Auto-generates docstrings; high-risk and currently prototype. |

Keep this table synchronized with `shared/tool_metadata.py` and update both when tiers or trust levels change.

---

## 5. Operating Standards and Maintenance

- Follow the audit-first workflow (see [AI_DEVELOPMENT_WORKFLOW.md](ai_development_docs/AI_DEVELOPMENT_WORKFLOW.md)) before touching documentation or infrastructure
- Keep the standard exclusions + config aligned so `.ruff_cache`, `mhm.egg-info`, `scripts`, `tests/ai/results`, and `tests/coverage_html` are skipped by the majority of analyzer runs.
- **Duplicate function analysis** (`development_tools/functions/analyze_duplicate_functions.py`):
  - **Exclusion**: To stop the analyzer from reporting a function as part of a duplicate group (e.g. intentional thin wrappers that delegate to a shared helper), add inside the function: `# duplicate_functions_exclude` or `# duplicate functions exclude` (optionally with a reason after a colon). Excluded functions are not paired with any other and do not appear in duplicate groups. See the tool docstring for details.
  - **Settings** (from `analyze_duplicate_functions` config): `use_mtime_cache` (reuse cached per-file signatures when mtimes match); `min_name_similarity` (minimum name-token overlap for a candidate pair); `min_overall_similarity` (minimum weighted similarity to report); `max_pairs` / `max_groups` (cap reported output); `max_candidate_pairs` / `max_token_group_size` (safety limits); `stop_name_tokens`; `weights` (name/args/locals/imports).
- **Caching Infrastructure**:
- **File-based caching**: Use `shared/mtime_cache.py` (`MtimeFileCache`) for file-based analyzers to cache results based on file modification times. This significantly speeds up repeated runs by only re-processing changed files. The utility handles cache loading, saving, and validation automatically. Currently used by: `imports/analyze_unused_imports.py`, `imports/analyze_module_imports.py`, `functions/analyze_functions.py`, `error_handling/analyze_error_handling.py`, `docs/analyze_ascii_compliance.py`, `docs/analyze_missing_addresses.py`, `legacy/analyze_legacy_references.py` (compatibility scan), `docs/analyze_heading_numbering.py`, `docs/analyze_path_drift.py`, `docs/analyze_unconverted_links.py`, `tests/analyze_test_coverage.py` (coverage analysis caching). The cache automatically invalidates when `development_tools/config/development_tools_config.json` or the tool's source file changes, ensuring config and code updates are immediately reflected.
- **Test Coverage Caching**:
- **Coverage Analysis Caching**: `tests/analyze_test_coverage.py` Caches analysis results based on coverage JSON file mtime, saving ~2s on repeated analysis when coverage data hasn't changed.
- **Test-file coverage caching (Integrated, enabled by default)**: `tests/test_file_coverage_cache.py` uses `tests/domain_mapper.py` (`DomainMapper`) to map source directories to test files. When a domain changes, only the test files that cover that domain are re-run, and cached coverage is merged for unchanged tests. Cache file: `development_tools/tests/jsons/test_file_coverage_cache.json`. Disable with `--no-domain-cache`.
- **Dev tools coverage caching (Integrated, enabled by default)**: `tests/dev_tools_coverage_cache.py` caches development_tools coverage JSON keyed by dev tools source mtimes. Cache file: `development_tools/tests/jsons/dev_tools_coverage_cache.json`. Disable with `--no-domain-cache`.
- **Parallel Execution**: Tools run in parallel where possible to reduce audit time:
- **Tier 2**: Independent tools (5 tools) run in parallel; dependent groups run sequentially within groups but in parallel with each other
- **Tier 3**: Coverage tools (main tests and dev tools tests) run in parallel (~365s max); legacy reference group runs in parallel with coverage tools; coverage-dependent tools (marker analysis, report generation) run sequentially after coverage completes
- **Tool Dependencies**: Some tools must run together due to dependencies (e.g., analysis -> report, imports -> patterns/dependencies). Coverage-dependent tools require data from both test suites, so they run after coverage completes. See `development_tools/shared/service/audit_orchestration.py` for dependency groupings.
- **Output Format Standardization**: All 19 analysis tools output JSON in a standardized structure with `summary` (total_issues, files_affected, status) and `details` (tool-specific data). This enables consistent data aggregation and simplified report generation. Tools support `--json` flag for direct standard format output. Results are validated against the standard format in `shared/result_format.py`.
- When adding or relocating tools, update:
- `shared/tool_metadata.py`
- This guide and the AI guide (paired H2 requirements)
- [AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md](development_tools/AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md) if scope or gaps change
- Maintain directory integrity (`development_tools/`, `ai_development_docs/`, `development_docs/`, `development_tools/reports/archive/`, `development_tools/tests/logs/`) so automation can locate artifacts; keep generated reports under the paths enumerated in `shared/constants.py`.
- Use the shared test locations: `tests/development_tools/` for suites and `tests/fixtures/development_tools_demo/` for synthetic inputs.
- For detailed testing guidance, see [DEVELOPMENT_TOOLS_TESTING_GUIDE.md](tests/DEVELOPMENT_TOOLS_TESTING_GUIDE.md).
- Context-specific behavior:
- `development_tools/config/config.py` defines production / development / testing contexts; commands must honor the active context.
- Never hardcode project paths - always resolve via `shared/common.py` helpers.
- Run `python development_tools/run_development_tools.py doc-sync` after documentation edits to ensure heading parity and ASCII compliance.
- Treat experimental tools (`docs/fix_version_sync.py`, `functions/generate_function_docstrings.py`, etc.) as opt-in: dry-run first, capture logs, and record findings in [TODO.md](TODO.md) or the improvement plan.
- Keep file organization portable (mirroring `development_tools/`, `ai_development_docs/`, `development_docs/`, `development_tools/reports/archive/`, `development_tools/tests/logs/`) to support eventual extraction of the suite. The baseline structure should remain:

```
development_tools/
ai_development_docs/
development_docs/
tests/development_tools/
tests/fixtures/development_tools_demo/
development_tools/reports/archive/
development_tools/tests/logs/
```

- Do not implement bespoke exclusion logic inside individual tools - always import from `shared/standard_exclusions.py` so rules remain centralized.
- Treat the tooling as a self-contained subproject: track follow-up work in [AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md](development_tools/AI_DEV_TOOLS_IMPROVEMENT_PLAN_V4.md), document shipped changes in both changelogs, and keep the AI + human guides synchronized.

Keeping these standards ensures the tooling ecosystem remains predictable for both humans and AI collaborators.

---

## 6. Generated File Metadata Standards

All files generated by the development tools suite must include standardized metadata to identify their origin, generation details, and purpose. This ensures consistency and traceability across all generated artifacts.

### 6.1. Markdown Files (.md)

All generated Markdown files must use this standardized metadata format at the beginning of the file:

```markdown
# Document Title

> **File**: `path/to/file.md`
> **Generated**: This file is auto-generated. Do not edit manually.
> **Last Generated**: YYYY-MM-DD HH:MM:SS
> **Source**: `python development_tools/path/to/generator.py` - Tool Description
> **Audience**: [Target audience, e.g., "Human developer and AI collaborators"]
> **Purpose**: [What this document is for]
> **Status**: **ACTIVE** - [Brief status note]
```

**Required fields:**
- `File`: Full path from project root
- `Generated`: Standard warning message
- `Last Generated`: Timestamp in `YYYY-MM-DD HH:MM:SS` format
- `Source`: Command and tool description
- `Audience`: Target audience (optional but recommended)
- `Purpose`: Document purpose (optional but recommended)
- `Status`: Current status (optional but recommended)

**Files using this standard:**
- `development_docs/FUNCTION_REGISTRY_DETAIL.md`
- `development_docs/MODULE_DEPENDENCIES_DETAIL.md`
- `development_docs/LEGACY_REFERENCE_REPORT.md`
- `development_docs/UNUSED_IMPORTS_REPORT.md`
- `development_docs/TEST_COVERAGE_REPORT.md`
- `development_docs/DIRECTORY_TREE.md`
- `ai_development_docs/AI_FUNCTION_REGISTRY.md`
- `ai_development_docs/AI_MODULE_DEPENDENCIES.md`
- `development_tools/AI_STATUS.md`
- `development_tools/AI_PRIORITIES.md`
- `development_tools/consolidated_report.txt`

### 6.2. JSON Files (.json)

All generated JSON files must include standardized metadata fields at the root level:

```json
{
"generated_by": "Tool Name - Tool Description",
"last_generated": "YYYY-MM-DD HH:MM:SS",
"source": "python development_tools/path/to/tool.py [command]",
"note": "This file is auto-generated. Do not edit manually.",
"timestamp": "YYYY-MM-DDTHH:MM:SS.ffffff",...
}
```

**Required fields:**
- `generated_by`: Tool name and description
- `last_generated`: Human-readable timestamp in `YYYY-MM-DD HH:MM:SS` format
- `source`: Command used to generate the file
- `note`: Standard warning message
- `timestamp`: ISO 8601 timestamp for programmatic use

**Files using this standard:**
- `development_tools/reports/analysis_detailed_results.json`
- `development_tools/error_handling/error_handling_details.json`
- `development_tools/config/analyze_config_results.json`

**Note:** Some JSON files are generated by external tools (e.g., `coverage.json` and `coverage_dev_tools.json` by pytest/coverage, located in `development_tools/tests/jsons/`) and may not follow this internal metadata standard. Only files generated by the development tools suite should include this metadata.

For documentation-specific metadata standards, see section 5.1 in [DOCUMENTATION_GUIDE.md](DOCUMENTATION_GUIDE.md).
