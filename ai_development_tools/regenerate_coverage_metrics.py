#!/usr/bin/env python3
"""
Test Coverage Metrics Regenerator for MHM

This script regenerates test coverage metrics and updates the 
TEST_COVERAGE_EXPANSION_PLAN.md with current data.

Usage:
    python ai_tools/regenerate_coverage_metrics.py [--update-plan] [--output-file]
"""

import argparse
import configparser
import json
import os
import re
import shutil
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from core.logger import get_component_logger

logger = get_component_logger(__name__)

class CoverageMetricsRegenerator:
    """Regenerates test coverage metrics for MHM."""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.coverage_plan_file = self.project_root / "development_docs" / "TEST_COVERAGE_EXPANSION_PLAN.md"
        self.coverage_config_path = self.project_root / "coverage.ini"
        self.coverage_data_file: Path = self.project_root / ".coverage"
        self.coverage_html_dir: Path = self.project_root / "htmlcov"
        self.coverage_logs_dir: Path = self.project_root / "ai_development_tools" / "logs" / "coverage_regeneration"
        self.pytest_stdout_log: Optional[Path] = None
        self.pytest_stderr_log: Optional[Path] = None
        self.archived_directories: List[Dict[str, str]] = []
        self.command_logs: List[Path] = []
        self._configure_coverage_paths()
        self._migrate_legacy_logs()
        self.coverage_logs_dir.mkdir(parents=True, exist_ok=True)
        
        # Core modules to track coverage for
        self.core_modules = [
            'core',
            'communication', 
            'ui',
            'tasks',
            'user',
            'ai'
        ]
        
    def _configure_coverage_paths(self) -> None:
        """Load coverage configuration paths from coverage.ini."""
        if not self.coverage_config_path.exists():
            # Fall back to defaults
            self.coverage_data_file = self.project_root / ".coverage"
            self.coverage_html_dir = self.project_root / "htmlcov"
            return
        
        config = configparser.ConfigParser()
        config.read(self.coverage_config_path)
        
        data_file = config.get('run', 'data_file', fallback='').strip()
        if data_file:
            self.coverage_data_file = (self.coverage_config_path.parent / data_file).resolve()
        else:
            self.coverage_data_file = self.project_root / ".coverage"
        
        html_directory = config.get('html', 'directory', fallback='').strip()
        if html_directory:
            self.coverage_html_dir = (self.coverage_config_path.parent / html_directory).resolve()
        else:
            self.coverage_html_dir = self.project_root / "htmlcov"
        
        # Ensure parent directories exist when we later write artefacts
        self.coverage_data_file.parent.mkdir(parents=True, exist_ok=True)
        self.coverage_html_dir.parent.mkdir(parents=True, exist_ok=True)

    def run_coverage_analysis(self) -> Dict[str, Dict[str, any]]:
        """Run pytest coverage analysis and extract metrics."""
        if logger:
            logger.info("Running pytest coverage analysis...")
        
        try:
            self.archived_directories.clear()
            self.command_logs.clear()
            self.pytest_stdout_log = None
            self.pytest_stderr_log = None
            
            coverage_output = self.project_root / "ai_development_tools" / "coverage.json"
            cmd = [
                sys.executable, '-m', 'pytest',
                '--cov=core',
                '--cov=communication',
                '--cov=ui',
                '--cov=tasks',
                '--cov=user',
                '--cov=ai',
                '--cov-report=term-missing',
                f'--cov-report=json:{coverage_output}',
                '--cov-config=coverage.ini',
                '--tb=no',
                '-q',
                '--maxfail=5',
                'tests/'
            ]
            
            env = os.environ.copy()
            env['COVERAGE_FILE'] = str(self.coverage_data_file)
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=self.project_root,
                env=env
            )
            
            self._record_pytest_output(result)
            
            if result.returncode != 0 and logger:
                logger.warning(
                    f"Coverage analysis completed with issues (exit code {result.returncode}). See {self.pytest_stderr_log} for stderr."
                )
            
            coverage_data = self.parse_coverage_output(result.stdout)
            if not coverage_data and coverage_output.exists():
                coverage_data = self._load_coverage_json(coverage_output)
            
            overall_coverage = self.extract_overall_coverage(result.stdout)
            if not overall_coverage.get('overall_coverage') and coverage_output.exists():
                overall_coverage = self._extract_overall_from_json(coverage_output)
            
            try:
                self.finalize_coverage_outputs()
            except Exception as finalize_error:
                if logger:
                    logger.warning(f"Failed to finalize coverage artefacts: {finalize_error}")
            
            return {
                'modules': coverage_data,
                'overall': overall_coverage,
                'logs': {
                    'stdout': str(self.pytest_stdout_log) if self.pytest_stdout_log else None,
                    'stderr': str(self.pytest_stderr_log) if self.pytest_stderr_log else None,
                },
                'archived_directories': self.archived_directories,
                'command_logs': [str(path) for path in self.command_logs]
            }
            
        except Exception as e:
            if logger:
                logger.error(f"Error running coverage analysis: {e}")
            else:
                print(f"Error running coverage analysis: {e}")
            return {}

    def _record_pytest_output(self, result: subprocess.CompletedProcess) -> None:
        """Persist pytest stdout/stderr for troubleshooting."""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        self.coverage_logs_dir.mkdir(parents=True, exist_ok=True)
        
        stdout_content = result.stdout or ""
        stderr_content = result.stderr or ""
        
        stdout_path = self.coverage_logs_dir / f"pytest_stdout_{timestamp}.log"
        stderr_path = self.coverage_logs_dir / f"pytest_stderr_{timestamp}.log"
        stdout_latest = self.coverage_logs_dir / "pytest_stdout.latest.log"
        stderr_latest = self.coverage_logs_dir / "pytest_stderr.latest.log"
        
        stdout_path.write_text(stdout_content, encoding='utf-8', errors='ignore')
        stderr_path.write_text(stderr_content, encoding='utf-8', errors='ignore')
        stdout_latest.write_text(stdout_content, encoding='utf-8', errors='ignore')
        stderr_latest.write_text(stderr_content, encoding='utf-8', errors='ignore')
        
        self.pytest_stdout_log = stdout_path
        self.pytest_stderr_log = stderr_path
        
        if logger:
            logger.info(f"Saved pytest output to {stdout_path} and {stderr_path}")
    
    def parse_coverage_output(self, output: str) -> Dict[str, Dict[str, any]]:
        """Parse the coverage output to extract module-specific metrics."""
        coverage_data = {}
        
        # Split output into sections
        sections = output.split('Name')
        if len(sections) < 2:
            return coverage_data
            
        coverage_section = sections[1]
        lines = coverage_section.strip().split('\n')
        
        for line in lines:
            if '---' in line or not line.strip():
                continue
                
            # Parse coverage line
            parts = line.split()
            if len(parts) >= 4:
                try:
                    module_name = parts[0]
                    statements = int(parts[1])
                    missed = int(parts[2])
                    coverage = int(parts[3].rstrip('%'))
                    
                    # Extract missing line numbers if available
                    missing_lines = []
                    if len(parts) > 4:
                        missing_part = ' '.join(parts[4:])
                        missing_lines = self.extract_missing_lines(missing_part)
                    
                    coverage_data[module_name] = {
                        'statements': statements,
                        'missed': missed,
                        'coverage': coverage,
                        'missing_lines': missing_lines,
                        'covered': statements - missed
                    }
                    
                except (ValueError, IndexError):
                    continue
                    
        return coverage_data

    def _load_coverage_json(self, json_path: Path) -> Dict[str, Dict[str, any]]:
        """Fallback parser that reads module metrics from coverage JSON output."""
        try:
            with open(json_path, 'r', encoding='utf-8') as json_file:
                data = json.load(json_file)
        except (FileNotFoundError, json.JSONDecodeError) as exc:
            if logger:
                logger.warning(f"Unable to load coverage JSON data: {exc}")
            return {}
        
        files = data.get('files', {})
        coverage_data: Dict[str, Dict[str, any]] = {}
        
        for module_name, file_data in files.items():
            summary = file_data.get('summary', {})
            statements = int(summary.get('num_statements', 0))
            covered = int(summary.get('covered_lines', statements - summary.get('missing_lines', 0)))
            missed = int(summary.get('missing_lines', statements - covered))
            percent = summary.get('percent_covered')
            if isinstance(percent, float):
                percent_value = int(round(percent))
            else:
                try:
                    percent_value = int(percent)
                except (TypeError, ValueError):
                    percent_value = 0
            
            missing_lines = file_data.get('missing_lines', [])
            missing_line_strings = [str(line) for line in missing_lines]
            
            coverage_data[module_name] = {
                'statements': statements,
                'missed': missed,
                'coverage': percent_value,
                'missing_lines': missing_line_strings,
                'covered': covered
            }
        
        return coverage_data
    
    def extract_missing_lines(self, missing_part: str) -> List[str]:
        """Extract missing line numbers from coverage output."""
        missing_lines = []
        
        # Look for patterns like "1-5, 10, 15-20"
        line_patterns = [
            r'(\d+)-(\d+)',  # Range like "1-5"
            r'(\d+)',        # Single line like "10"
        ]
        
        for pattern in line_patterns:
            matches = re.findall(pattern, missing_part)
            for match in matches:
                if len(match) == 2:  # Range
                    start, end = int(match[0]), int(match[1])
                    missing_lines.extend([str(i) for i in range(start, end + 1)])
                else:  # Single line
                    missing_lines.append(match[0])
                    
        return missing_lines
    
    def extract_overall_coverage(self, output: str) -> Dict[str, any]:
        """Extract overall coverage metrics."""
        overall_data = {
            'total_statements': 0,
            'total_missed': 0,
            'overall_coverage': 0
        }
        
        # Look for TOTAL line
        total_pattern = r'TOTAL\s+(\d+)\s+(\d+)\s+(\d+)%'
        match = re.search(total_pattern, output)
        
        if match:
            overall_data['total_statements'] = int(match.group(1))
            overall_data['total_missed'] = int(match.group(2))
            overall_data['overall_coverage'] = int(match.group(3))
            
        return overall_data

    def _extract_overall_from_json(self, json_path: Path) -> Dict[str, any]:
        """Compute overall coverage using the JSON report."""
        try:
            with open(json_path, 'r', encoding='utf-8') as json_file:
                data = json.load(json_file)
        except (FileNotFoundError, json.JSONDecodeError):
            return {
                'total_statements': 0,
                'total_missed': 0,
                'overall_coverage': 0
            }
        
        files = data.get('files', {})
        total_statements = 0
        total_missed = 0
        
        for file_data in files.values():
            summary = file_data.get('summary', {})
            total_statements += int(summary.get('num_statements', 0))
            total_missed += int(summary.get('missing_lines', 0))
        
        if total_statements:
            percent = int(round((total_statements - total_missed) / total_statements * 100))
        else:
            percent = 0
        
        return {
            'total_statements': total_statements,
            'total_missed': total_missed,
            'overall_coverage': percent
        }

    def finalize_coverage_outputs(self) -> None:
        """Combine coverage data, generate HTML, and clean up artefacts."""
        env = os.environ.copy()
        env['COVERAGE_FILE'] = str(self.coverage_data_file)
        if self.coverage_config_path.exists():
            env['COVERAGE_RCFILE'] = str(self.coverage_config_path)
        
        coverage_cmd = [sys.executable, '-m', 'coverage']
        
        shard_paths = self._collect_shard_paths()
        if shard_paths:
            combine_dirs = {
                self.project_root.resolve(),
                self.coverage_data_file.parent.resolve()
            }
            combine_args = coverage_cmd + ['combine'] + [str(path) for path in combine_dirs]
            combine_result = subprocess.run(
                combine_args,
                capture_output=True,
                text=True,
                cwd=self.project_root,
                env=env
            )
            self._write_command_log('coverage_combine', combine_result)
            if combine_result.returncode != 0:
                stdout_message = (combine_result.stdout or "").strip()
                stderr_message = (combine_result.stderr or "").strip()
                if "No data to combine" in stdout_message:
                    if logger:
                        logger.info("coverage combine reported no data to combine; continuing.")
                elif logger:
                    logger.warning(
                        f"coverage combine exited with {combine_result.returncode}: {stderr_message or stdout_message}"
                    )
        else:
            skip_message = "Skipped coverage combine: no shard files detected."
            self._write_text_log('coverage_combine', skip_message)
            if logger:
                logger.info(skip_message)
        
        # Generate HTML report in the canonical directory
        if self.coverage_html_dir.exists():
            shutil.rmtree(self.coverage_html_dir)
        self.coverage_html_dir.mkdir(parents=True, exist_ok=True)
        
        html_args = coverage_cmd + ['html', '-d', str(self.coverage_html_dir)]
        html_result = subprocess.run(
            html_args,
            capture_output=True,
            text=True,
            cwd=self.project_root,
            env=env
        )
        self._write_command_log('coverage_html', html_result)
        if html_result.returncode != 0 and logger:
            logger.warning(
                f"coverage html exited with {html_result.returncode}: {html_result.stderr.strip()}"
            )
        
        self._cleanup_coverage_shards()
        self._archive_legacy_html_dirs()
        self._cleanup_shutdown_flag()

    def _write_command_log(self, command_name: str, result: subprocess.CompletedProcess) -> None:
        """Persist stdout/stderr for coverage helper commands."""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        log_path = self.coverage_logs_dir / f"{command_name}_{timestamp}.log"
        latest_path = self.coverage_logs_dir / f"{command_name}.latest.log"
        
        content_lines = [
            f"# Command: {command_name}",
            f"# Return code: {result.returncode}",
            "",
            "## STDOUT",
            result.stdout or "",
            "",
            "## STDERR",
            result.stderr or ""
        ]
        log_text = "\n".join(content_lines)
        log_path.write_text(log_text, encoding='utf-8', errors='ignore')
        latest_path.write_text(log_text, encoding='utf-8', errors='ignore')
        self.command_logs.append(log_path)
        
        if logger:
            logger.info(f"Saved {command_name} logs to {log_path}")

    def _write_text_log(self, log_name: str, message: str) -> None:
        """Create a simple log file with a message."""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        log_path = self.coverage_logs_dir / f"{log_name}_{timestamp}.log"
        latest_path = self.coverage_logs_dir / f"{log_name}.latest.log"
        content = f"# {log_name.replace('_', ' ').title()}\n\n{message}\n"
        log_path.write_text(content, encoding='utf-8', errors='ignore')
        latest_path.write_text(content, encoding='utf-8', errors='ignore')
        self.command_logs.append(log_path)

    def _collect_shard_paths(self) -> List[Path]:
        """Return a list of coverage shard files currently on disk."""
        shard_paths: List[Path] = []
        patterns = [
            self.project_root.glob('.coverage.*'),
            self.coverage_data_file.parent.glob(f"{self.coverage_data_file.name}.*")
        ]
        for iterator in patterns:
            for shard in iterator:
                if shard.exists():
                    shard_paths.append(shard)
        return shard_paths

    def _cleanup_coverage_shards(self) -> None:
        """Remove leftover .coverage.* files to prevent stale data."""
        removed = 0
        for shard in self._collect_shard_paths():
            try:
                shard.unlink()
                removed += 1
            except FileNotFoundError:
                continue
        
        # Remove root .coverage if different from configured data file
        root_coverage = self.project_root / ".coverage"
        if root_coverage.exists() and root_coverage.resolve() != self.coverage_data_file.resolve():
            try:
                root_coverage.unlink()
                removed += 1
            except FileNotFoundError:
                pass
        
        if logger and removed:
            logger.info(f"Removed {removed} stale coverage shard(s)")

    def _migrate_legacy_logs(self) -> None:
        """Move legacy coverage logs from the old location into the new directory."""
        legacy_dir = self.project_root / "logs" / "coverage_regeneration"
        if not legacy_dir.exists() or legacy_dir.resolve() == self.coverage_logs_dir.resolve():
            return
        
        self.coverage_logs_dir.mkdir(parents=True, exist_ok=True)
        for item in legacy_dir.iterdir():
            destination = self.coverage_logs_dir / item.name
            try:
                if destination.exists():
                    # Preserve existing new-format logs by appending timestamp suffix
                    suffix = datetime.now().strftime("%Y%m%d-%H%M%S")
                    destination = self.coverage_logs_dir / f"{destination.stem}_{suffix}{destination.suffix}"
                shutil.move(str(item), str(destination))
            except Exception as exc:
                if logger:
                    logger.warning(f"Failed to migrate legacy log {item}: {exc}")
        
        try:
            legacy_dir.rmdir()
        except OSError:
            # Directory not empty (maybe concurrent process); leave it alone
            pass

    def _archive_legacy_html_dirs(self) -> None:
        """Archive and remove redundant legacy coverage HTML directories."""
        legacy_dirs = [
            self.project_root / "htmlcov",
            self.project_root / "tests" / "coverage_html",
            self.project_root / "tests" / "htmlcov"
        ]
        archive_root = self.project_root / "archive" / "coverage_artifacts"
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        
        for legacy_dir in legacy_dirs:
            if not legacy_dir.exists():
                continue
            
            # Skip if this directory is the canonical destination
            if legacy_dir.resolve() == self.coverage_html_dir.resolve():
                continue
            
            destination = archive_root / timestamp / legacy_dir.name
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            if destination.exists():
                shutil.rmtree(destination)
            
            shutil.move(str(legacy_dir), str(destination))
            self.archived_directories.append({
                'source': str(legacy_dir),
                'destination': str(destination)
            })
            
            if logger:
                logger.info(f"Archived legacy coverage directory {legacy_dir} -> {destination}")

    def _cleanup_shutdown_flag(self) -> None:
        """Remove the transient shutdown_request.flag file if it was created."""
        flag_path = self.project_root / "shutdown_request.flag"
        if flag_path.exists():
            try:
                flag_path.unlink()
                if logger:
                    logger.info("Removed stray shutdown_request.flag")
            except OSError as exc:
                if logger:
                    logger.warning(f"Unable to remove shutdown_request.flag: {exc}")
    
    def categorize_modules(self, coverage_data: Dict[str, Dict[str, any]]) -> Dict[str, List[str]]:
        """Categorize modules by coverage level."""
        categories = {
            'excellent': [],      # 80%+
            'good': [],           # 60-79%
            'moderate': [],       # 40-59%
            'needs_work': [],     # 20-39%
            'critical': []        # <20%
        }
        
        for module_name, data in coverage_data.items():
            coverage = data['coverage']
            
            if coverage >= 80:
                categories['excellent'].append(module_name)
            elif coverage >= 60:
                categories['good'].append(module_name)
            elif coverage >= 40:
                categories['moderate'].append(module_name)
            elif coverage >= 20:
                categories['needs_work'].append(module_name)
            else:
                categories['critical'].append(module_name)
                
        return categories
    
    def generate_coverage_summary(self, coverage_data: Dict[str, Dict[str, any]], 
                                overall_data: Dict[str, any]) -> str:
        """Generate a coverage summary for the plan."""
        summary_lines = []
        
        # Overall coverage
        summary_lines.append(f"### **Overall Coverage: {overall_data['overall_coverage']}%**")
        summary_lines.append(f"- **Total Statements**: {overall_data['total_statements']:,}")
        summary_lines.append(f"- **Covered Statements**: {overall_data['total_statements'] - overall_data['total_missed']:,}")
        summary_lines.append(f"- **Uncovered Statements**: {overall_data['total_missed']:,}")
        summary_lines.append(f"- **Goal**: Expand to **80%+ coverage** for comprehensive reliability\n")
        
        # Coverage by category
        categories = self.categorize_modules(coverage_data)
        
        summary_lines.append("### **Coverage Summary by Category**")
        
        for category, modules in categories.items():
            if modules:
                avg_coverage = sum(coverage_data[m]['coverage'] for m in modules) / len(modules)
                summary_lines.append(f"- **{category.title()} ({avg_coverage:.0f}% avg)**: {len(modules)} modules")
                
        summary_lines.append("")
        
        # Detailed module breakdown
        summary_lines.append("### **Detailed Module Coverage**")
        
        # Sort modules by coverage (lowest first)
        sorted_modules = sorted(coverage_data.items(), key=lambda x: x[1]['coverage'])
        
        for module_name, data in sorted_modules:
            status_emoji = "*" if data['coverage'] >= 80 else "!" if data['coverage'] >= 60 else "X"
            summary_lines.append(f"- **{status_emoji} {module_name}**: {data['coverage']}% ({data['covered']}/{data['statements']} lines)")
            
        return '\n'.join(summary_lines)
    
    def update_coverage_plan(self, coverage_summary: str) -> bool:
        """Update the TEST_COVERAGE_EXPANSION_PLAN.md with new metrics."""
        if not self.coverage_plan_file.exists():
            if logger:
                logger.error(f"Coverage plan file not found: {self.coverage_plan_file}")
            return False
            
        try:
            with open(self.coverage_plan_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Find and replace the current status section
            section_header = "## Current Status"
            current_status_pattern = r'(## Current Status.*?)(?=\n## |\Z)'
            
            new_status_section = f"{section_header}\n\n{coverage_summary}\n"
            
            if re.search(current_status_pattern, content, re.DOTALL):
                # Replace existing status section
                updated_content = re.sub(
                    current_status_pattern,
                    lambda _: new_status_section,
                    content,
                    flags=re.DOTALL
                )
            else:
                # Add new status section after the header
                header_pattern = r'(# Test Coverage Expansion Plan.*?\n)'
                match = re.search(header_pattern, content, re.DOTALL)
                if match:
                    insert_pos = match.end()
                    updated_content = content[:insert_pos] + '\n' + new_status_section + content[insert_pos:]
                else:
                    # Fallback: add at beginning
                    updated_content = new_status_section + '\n\n' + content
            
            # Update the last updated timestamp
            timestamp_pattern = r'(> \*\*Last Updated\*\*: ).*'
            current_time = self.get_current_timestamp()
            if re.search(timestamp_pattern, updated_content):
                updated_content = re.sub(
                    timestamp_pattern,
                    lambda match: f"{match.group(1)}{current_time}",
                    updated_content
                )
            else:
                updated_content = f"> **Last Updated**: {current_time}\n\n" + updated_content
            
            # Write updated content
            with open(self.coverage_plan_file, 'w', encoding='utf-8') as plan_file:
                plan_file.write(updated_content)
                
            if logger:
                logger.info(f"Updated coverage plan: {self.coverage_plan_file}")
            return True
            
        except Exception as e:
            if logger:
                logger.error(f"Error updating coverage plan: {e}")
            return False
    
    def get_current_timestamp(self) -> str:
        """Get current timestamp in the format used by the plan."""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d")
    
    def run(self, update_plan: bool = False) -> Dict[str, any]:
        """Run the coverage metrics regeneration."""
        logger.info("Starting coverage metrics regeneration...")
        
        # Run coverage analysis
        coverage_results = self.run_coverage_analysis()
        
        if not coverage_results:
            logger.error("Failed to get coverage data")
            return {}
        
        # Generate summary
        coverage_summary = self.generate_coverage_summary(
            coverage_results['modules'], 
            coverage_results['overall']
        )
        
        # Print summary (headers removed - added by consolidated report)
        print(coverage_summary)
        
        # Update plan if requested
        if update_plan:
            success = self.update_coverage_plan(coverage_summary)
            if success:
                print("\n* Coverage plan updated successfully!")
            else:
                print("\n* Failed to update coverage plan")
        
        return coverage_results


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(description="Regenerate test coverage metrics")
    parser.add_argument('--update-plan', action='store_true', 
                       help='Update TEST_COVERAGE_EXPANSION_PLAN.md with new metrics')
    parser.add_argument('--output-file', help='Output file for coverage report (optional)')
    
    args = parser.parse_args()
    
    regenerator = CoverageMetricsRegenerator()
    results = regenerator.run(update_plan=args.update_plan)
    
    if args.output_file and results:
        # Save detailed results to JSON file
        output_path = Path(args.output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            import json
            json.dump(results, f, indent=2)
        print(f"\n📊 Detailed coverage data saved to: {output_path}")


if __name__ == "__main__":
    main()
