#!/usr/bin/env python3
"""
Generate and update MODULE_DEPENDENCIES.md automatically.
Scans all .py files and creates comprehensive module dependency documentation.
"""

import os
import ast
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
import json
from datetime import datetime

def extract_imports_from_file(file_path: str) -> Dict[str, List[Dict]]:
    """Extract all imports from a Python file with detailed information."""
    imports = {
        'standard_library': [],
        'third_party': [],
        'local': []
    }
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        tree = ast.parse(content)
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    module_name = alias.name
                    import_info = {
                        'module': module_name,
                        'as_name': alias.asname,
                        'imported_items': [module_name]  # For direct imports, the module itself
                    }
                    
                    if is_standard_library(module_name):
                        imports['standard_library'].append(import_info)
                    elif is_local_import(module_name):
                        imports['local'].append(import_info)
                    else:
                        imports['third_party'].append(import_info)
                        
            elif isinstance(node, ast.ImportFrom):
                module_name = node.module
                if module_name:
                    # Extract specific imported items
                    imported_items = []
                    for alias in node.names:
                        if alias.name == '*':
                            imported_items.append('*')
                        else:
                            imported_items.append(alias.name)
                    
                    import_info = {
                        'module': module_name,
                        'as_name': None,  # ImportFrom doesn't have module-level aliases
                        'imported_items': imported_items
                    }
                    
                    if is_standard_library(module_name):
                        imports['standard_library'].append(import_info)
                    elif is_local_import(module_name):
                        imports['local'].append(import_info)
                    else:
                        imports['third_party'].append(import_info)
                
    except Exception as e:
        print(f"Error parsing {file_path}: {e}")
    
    return imports

def is_standard_library(module_name: str) -> bool:
    """Check if a module is part of the Python standard library."""
    standard_lib_modules = {
        'os', 'sys', 'json', 'time', 'datetime', 'pathlib', 'typing', 're', 'uuid',
        'shutil', 'zipfile', 'threading', 'asyncio', 'socket', 'psutil', 'requests',
        'logging', 'warnings', 'subprocess', 'signal', 'atexit', 'random', 'hashlib',
        'email', 'smtplib', 'urllib', 'http', 'ssl', 'pytz', 'calendar', 'math',
        'statistics', 'collections', 'itertools', 'functools', 'contextlib'
    }
    
    # Check if it's a standard library module
    if module_name in standard_lib_modules:
        return True
    
    # Check if it starts with common standard library prefixes
    std_prefixes = ['os.', 'sys.', 'json.', 'time.', 'datetime.', 'pathlib.', 'typing.']
    return any(module_name.startswith(prefix) for prefix in std_prefixes)

def is_local_import(module_name: str) -> bool:
    """Check if a module is a local import (part of our project)."""
    local_prefixes = ['core.', 'bot.', 'ui.', 'user.', 'tasks.', 'scripts.', 'tests.']
    return any(module_name.startswith(prefix) for prefix in local_prefixes)

def format_import_details(import_info: Dict) -> str:
    """Format import information for display."""
    module = import_info['module']
    imported_items = import_info['imported_items']
    
    if imported_items == [module] or '*' in imported_items:
        # Direct import or wildcard import
        return module
    else:
        # Specific items imported
        items_str = ', '.join(imported_items)
        return f"{module} ({items_str})"

def scan_all_python_files() -> Dict[str, Dict]:
    """Scan all Python files in the project and extract import information."""
    project_root = Path(__file__).parent.parent
    results = {}
    
    # Directories to scan (excluding scripts as requested)
    scan_dirs = ['core', 'bot', 'ui', 'user', 'tasks', 'tests']
    
    for scan_dir in scan_dirs:
        dir_path = project_root / scan_dir
        if not dir_path.exists():
            continue
            
        for py_file in dir_path.rglob('*.py'):
            relative_path = py_file.relative_to(project_root)
            file_key = str(relative_path).replace('\\', '/')
            
            imports = extract_imports_from_file(str(py_file))
            
            results[file_key] = {
                'imports': imports,
                'total_imports': sum(len(imp_list) for imp_list in imports.values())
            }
    
    # Also scan root directory for .py files
    for py_file in project_root.glob('*.py'):
        if py_file.name not in ['generate_function_registry.py', 'generate_module_dependencies.py']:
            file_key = py_file.name
            
            imports = extract_imports_from_file(str(py_file))
            
            results[file_key] = {
                'imports': imports,
                'total_imports': sum(len(imp_list) for imp_list in imports.values())
            }
    
    return results

def find_usage_of_module(target_module: str, all_modules: Dict[str, Dict]) -> List[str]:
    """Find all modules that use the target module."""
    users = []
    for file_path, data in all_modules.items():
        if target_module in data['imports']['local']:
            users.append(file_path)
    return sorted(users)

def find_reverse_dependencies(target_module: str, all_modules: Dict[str, Dict]) -> List[str]:
    """Find all modules that import the target module."""
    users = []
    
    # Convert file path to module name (e.g., 'core/config.py' -> 'core.config')
    module_name = target_module.replace('/', '.').replace('.py', '')
    
    for file_path, data in all_modules.items():
        # Check local imports for the target module
        for import_info in data['imports']['local']:
            if import_info['module'] == module_name:
                users.append(file_path)
                break
    
    return sorted(users)

def analyze_dependency_changes(file_path: str, data: Dict, existing_content: str) -> Dict:
    """Analyze if dependencies have changed since last generation."""
    changes = {
        'added': [],
        'removed': [],
        'unchanged': True
    }
    
    # Extract current dependencies from the new structure
    current_deps = set()
    for import_info in data['imports']['local']:
        current_deps.add(import_info['module'])
    
    # Extract existing dependencies from content
    existing_deps = set()
    if existing_content:
        section_start = existing_content.find(f"#### `{file_path}`")
        if section_start != -1:
            next_section = existing_content.find("#### `", section_start + 1)
            if next_section == -1:
                section_end = len(existing_content)
            else:
                section_end = next_section
            
            section_content = existing_content[section_start:section_end]
            
            # Extract dependencies from the section
            for line in section_content.split('\n'):
                if line.strip().startswith('- `') and line.strip().endswith('`'):
                    dep = line.strip()[3:-1]  # Remove '- `' and '`'
                    if '.' in dep:  # Only count local dependencies
                        # Extract module name from formatted string (e.g., "core.error_handling (func1, func2)" -> "core.error_handling")
                        module_name = dep.split(' (')[0]
                        existing_deps.add(module_name)
    
    # Calculate changes
    added = current_deps - existing_deps
    removed = existing_deps - current_deps
    
    if added or removed:
        changes['unchanged'] = False
        changes['added'] = sorted(added)
        changes['removed'] = sorted(removed)
    
    return changes

def infer_module_purpose(file_path: str, data: Dict, all_modules: Dict[str, Dict]) -> str:
    """Infer a more detailed purpose based on dependencies and usage patterns."""
    # Extract local dependencies from the new structure
    local_deps = [import_info['module'] for import_info in data['imports']['local']]
    reverse_deps = find_reverse_dependencies(file_path, all_modules)
    
    # Analyze dependency patterns
    core_deps = [d for d in local_deps if d.startswith('core.')]
    bot_deps = [d for d in local_deps if d.startswith('bot.')]
    ui_deps = [d for d in local_deps if d.startswith('ui.')]
    test_deps = [d for d in local_deps if 'test' in d]
    
    # Infer purpose based on patterns
    if file_path.startswith('bot/'):
        if 'ai_chatbot' in file_path:
            return "AI chatbot implementation using LM Studio API"
        elif 'base_channel' in file_path:
            return "Abstract base class for communication channels"
        elif 'channel_factory' in file_path:
            return "Factory for creating communication channels"
        elif 'channel_registry' in file_path:
            return "Registry for all available communication channels"
        elif 'communication_manager' in file_path:
            return "Manages communication across all channels"
        elif 'conversation_manager' in file_path:
            return "Manages conversation flows and check-ins"
        elif 'discord_bot' in file_path:
            return "Discord bot implementation"
        elif 'email_bot' in file_path:
            return "Email bot implementation"
        elif 'telegram_bot' in file_path:
            return "Telegram bot implementation"
        elif 'user_context_manager' in file_path:
            return "Manages user context for AI conversations"
        else:
            return f"Communication channel implementation for {file_path.split('/')[-1].replace('.py', '')}"
    
    elif file_path.startswith('core/'):
        if 'config' in file_path:
            return "Configuration management and validation"
        elif 'error_handling' in file_path:
            return "Centralized error handling and recovery"
        elif 'file_operations' in file_path:
            return "File operations and data management"
        elif 'logger' in file_path:
            return "Logging system configuration and management"
        elif 'message_management' in file_path:
            return "Message management and storage"
        elif 'response_tracking' in file_path:
            return "Tracks user responses and interactions"
        elif 'schedule_management' in file_path:
            return "Schedule management and time period handling"
        elif 'scheduler' in file_path:
            return "Task scheduling and job management"
        elif 'service' in file_path:
            return "Main service orchestration and management"
        elif 'service_utilities' in file_path:
            return "Utility functions for service operations"
        elif 'ui_management' in file_path:
            return "UI management and widget utilities"
        elif 'user_data' in file_path:
            if 'handlers' in file_path:
                return "User data handlers with caching and validation"
            elif 'manager' in file_path:
                return "Enhanced user data management with references"
            elif 'validation' in file_path:
                return "User data validation and integrity checks"
        elif 'user_management' in file_path:
            return "Centralized user data access and management"
        elif 'validation' in file_path:
            return "Data validation utilities"
        elif 'auto_cleanup' in file_path:
            return "Automatic cache cleanup and maintenance"
        elif 'backup_manager' in file_path:
            return "Manages automatic backups and rollback operations"
        elif 'checkin_analytics' in file_path:
            return "Analyzes check-in data and provides insights"
        else:
            return f"Core system module for {file_path.split('/')[-1].replace('.py', '')}"
    
    elif file_path.startswith('ui/'):
        if 'dialogs' in file_path:
            return f"Dialog component for {file_path.split('/')[-1].replace('.py', '').replace('_', ' ')}"
        elif 'widgets' in file_path:
            return f"UI widget component for {file_path.split('/')[-1].replace('.py', '').replace('_', ' ')}"
        elif 'generated' in file_path:
            return f"Auto-generated UI component for {file_path.split('/')[-1].replace('.py', '').replace('_', ' ')}"
        elif 'ui_app' in file_path:
            return "Main UI application (PyQt6)"
        else:
            return f"User interface component for {file_path.split('/')[-1].replace('.py', '')}"
    
    elif file_path.startswith('tests/'):
        if 'behavior' in file_path:
            return f"Behavior tests for {file_path.split('/')[-1].replace('.py', '').replace('test_', '').replace('_', ' ')}"
        elif 'integration' in file_path:
            return f"Integration tests for {file_path.split('/')[-1].replace('.py', '').replace('test_', '').replace('_', ' ')}"
        elif 'unit' in file_path:
            return f"Unit tests for {file_path.split('/')[-1].replace('.py', '').replace('test_', '').replace('_', ' ')}"
        elif 'ui' in file_path:
            return f"UI tests for {file_path.split('/')[-1].replace('.py', '').replace('test_', '').replace('_', ' ')}"
        else:
            return f"Test file for {file_path.split('/')[-1].replace('.py', '').replace('test_', '').replace('_', ' ')}"
    
    elif file_path.startswith('user/'):
        if 'user_context' in file_path:
            return "User context management"
        elif 'user_preferences' in file_path:
            return "User preferences management"
        else:
            return f"User data module for {file_path.split('/')[-1].replace('.py', '')}"
    
    elif file_path.startswith('tasks/'):
        return "Task management and scheduling"
    
    elif file_path in ['run_mhm.py', 'run_tests.py']:
        if 'run_mhm' in file_path:
            return "Main entry point for the MHM application"
        elif 'run_tests' in file_path:
            return "Test runner for the MHM application"
    
    # Fallback based on dependency patterns
    if len(core_deps) > len(local_deps) * 0.7:
        return f"Core system module with heavy core dependencies"
    elif len(bot_deps) > 0:
        return f"Bot-related module with communication dependencies"
    elif len(ui_deps) > 0:
        return f"UI-related module with interface dependencies"
    elif len(test_deps) > 0:
        return f"Test-related module"
    else:
        return f"Module for {file_path}"

def generate_module_dependencies_content(actual_imports: Dict[str, Dict], existing_content: str = "") -> str:
    """Generate comprehensive module dependencies content with hybrid format."""
    content = []
    
    # Header
    content.append("# Module Dependencies - MHM Project")
    content.append("")
    content.append("> **Purpose**: Complete dependency map for all modules in the MHM codebase  ")
    content.append("> **Status**: **ACTIVE** - Hybrid auto-generated and manually enhanced  ")
    content.append("> **Last Updated**: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    content.append("")
    content.append("> **See [README.md](README.md) for complete navigation and project overview**")
    content.append("> **See [ARCHITECTURE.md](ARCHITECTURE.md) for system architecture and design**")
    content.append("> **See [TODO.md](TODO.md) for current documentation priorities**")
    content.append("")
    
    # Overview section
    total_files = len(actual_imports)
    total_imports = sum(data['total_imports'] for data in actual_imports.values())
    
    # Calculate import counts from the new structure
    local_imports = 0
    std_lib_imports = 0
    third_party_imports = 0
    
    for data in actual_imports.values():
        local_imports += len(data['imports']['local'])
        std_lib_imports += len(data['imports']['standard_library'])
        third_party_imports += len(data['imports']['third_party'])
    
    content.append("## üìã **Overview**")
    content.append("")
    content.append(f"### **Module Dependencies Coverage: 100.0% ‚úÖ COMPLETED**")
    content.append(f"- **Files Scanned**: {total_files}")
    content.append(f"- **Total Imports Found**: {total_imports}")
    content.append(f"- **Dependencies Documented**: {total_files} (100% coverage)")
    content.append(f"- **Standard Library Imports**: {std_lib_imports}")
    content.append(f"- **Third-Party Imports**: {third_party_imports}")
    content.append(f"- **Local Imports**: {local_imports}")
    content.append(f"- **Last Updated**: {datetime.now().strftime('%Y-%m-%d')}")
    content.append("")
    content.append("**Status**: ‚úÖ **COMPLETED** - All module dependencies have been documented with comprehensive dependency and usage information.")
    content.append("")
    content.append("**Note**: This dependency map uses a hybrid approach - auto-generated dependency information with manual enhancements for detailed descriptions and reverse dependencies.")
    content.append("")
    
    # Import statistics
    content.append("## üîç **Import Statistics**")
    content.append("")
    content.append(f"- **Standard Library**: {std_lib_imports} imports ({std_lib_imports/total_imports*100:.1f}%)")
    content.append(f"- **Third-party**: {third_party_imports} imports ({third_party_imports/total_imports*100:.1f}%)")
    content.append(f"- **Local**: {local_imports} imports ({local_imports/total_imports*100:.1f}%)")
    content.append("")
    
    # Group by directory
    content.append("## üìÅ **Module Dependencies by Directory**")
    content.append("")
    
    # Group files by directory
    dir_files = {}
    for file_path, data in actual_imports.items():
        dir_name = file_path.split('/')[0] if '/' in file_path else 'root'
        if dir_name not in dir_files:
            dir_files[dir_name] = []
        dir_files[dir_name].append((file_path, data))
    
    # Directory descriptions
    dir_descriptions = {
        'core': 'Core System Modules (Foundation)',
        'bot': 'Communication Channel Implementations',
        'ui': 'User Interface Components',
        'user': 'User Data and Context',
        'tasks': 'Task Management',
        'tests': 'Test Files',
        'root': 'Root Files'
    }
    
    for dir_name in sorted(dir_files.keys()):
        if dir_name in dir_descriptions:
            content.append(f"### `{dir_name}/` - {dir_descriptions[dir_name]}")
        else:
            content.append(f"### `{dir_name}/`")
        content.append("")
        
        # Sort files within directory
        dir_files[dir_name].sort(key=lambda x: x[0])
        
        for file_path, data in dir_files[dir_name]:
            content.extend(generate_module_section(file_path, data, actual_imports, existing_content))
            content.append("")
    
    return "\n".join(content)

def get_directory_description(dir_name: str) -> str:
    """Get a description for a directory."""
    descriptions = {
        'core': 'Core System Modules (Foundation)',
        'bot': 'Communication Channel Implementations', 
        'ui': 'User Interface Components',
        'user': 'User Data and Context',
        'tasks': 'Task Management',
        'tests': 'Test Files',
        'root': 'Root Files'
    }
    return descriptions.get(dir_name, 'Unknown Directory')

def get_module_purpose(file_path: str) -> str:
    """Get a purpose description for a module based on its path and name."""
    purposes = {
        # Core modules
        'core/config.py': 'Configuration management for MHM - handles environment variables, validation, and system settings',
        'core/error_handling.py': 'Comprehensive error handling system - provides centralized error handling, custom exceptions, and recovery strategies',
        'core/logger.py': 'Centralized logging system for the application',
        'core/file_operations.py': 'File operations utilities - contains functions for file I/O, path determination, and file management',
        'core/user_management.py': 'User management utilities - contains functions for managing user accounts, preferences, context, and schedules',
        'core/message_management.py': 'Message management system - handles message categories, content, and delivery',
        'core/schedule_management.py': 'Schedule management system - handles user schedules, periods, and timing',
        'core/user_data_handlers.py': 'User data handlers - provides centralized access to user data with caching and validation',
        'core/user_data_manager.py': 'User data manager - manages user data storage, retrieval, and caching',
        'core/user_data_validation.py': 'User data validation - validates user input and data integrity',
        'core/validation.py': 'Validation system - provides validation utilities and error handling',
        'core/response_tracking.py': 'Response tracking system - tracks user responses and interactions',
        'core/scheduler.py': 'Scheduler system - manages scheduled tasks and operations',
        'core/service.py': 'Main service - coordinates all system components and manages the application lifecycle',
        'core/service_utilities.py': 'Service utilities - provides utility functions for the service layer',
        'core/ui_management.py': 'UI management - manages user interface components and interactions',
        'core/auto_cleanup.py': 'Auto cleanup system - handles automatic cleanup of temporary files and data',
        'core/backup_manager.py': 'Backup manager - handles system backups and data protection',
        'core/checkin_analytics.py': 'Check-in analytics - analyzes user check-in patterns and provides insights',
        
        # Bot modules
        'bot/ai_chatbot.py': 'AI chatbot implementation using LM Studio API',
        'bot/base_channel.py': 'Abstract base class for all communication channels',
        'bot/channel_factory.py': 'Factory for creating communication channels',
        'bot/channel_registry.py': 'Registry for all available communication channels',
        'bot/communication_manager.py': 'Manages communication across all channels',
        'bot/conversation_manager.py': 'Manages conversation flows and check-ins',
        'bot/discord_bot.py': 'Discord bot implementation',
        'bot/email_bot.py': 'Email bot implementation',
        'bot/telegram_bot.py': 'Telegram bot implementation',
        'bot/user_context_manager.py': 'Manages user context for AI conversations',
        
        # User modules
        'user/user_context.py': 'User context management - manages user context and personal information',
        'user/user_preferences.py': 'User preferences management - manages user preferences and settings',
        
        # Task modules
        'tasks/task_management.py': 'Task management system - manages user tasks and to-do items',
        
        # Root files
        'run_mhm.py': 'Main entry point for the MHM application',
        'run_tests.py': 'Test runner for the MHM application',
    }
    
    return purposes.get(file_path, f'Module for {file_path}')

def generate_module_section(file_path: str, data: Dict, all_modules: Dict[str, Dict], existing_content: str = "") -> List[str]:
    """Generate a module section with enhanced automated analysis."""
    content = []
    
    # Enhanced purpose inference
    inferred_purpose = infer_module_purpose(file_path, data, all_modules)
    
    # Reverse dependency analysis
    reverse_deps = find_reverse_dependencies(file_path, all_modules)
    
    # Dependency change analysis
    dep_changes = analyze_dependency_changes(file_path, data, existing_content)
    
    # Auto-generated section marker
    content.append(f"#### `{file_path}`")
    
    # Enhanced purpose
    content.append(f"- **Purpose**: {inferred_purpose}")
    
    # Dependencies with enhanced details
    local_deps = data['imports']['local']
    std_lib_deps = data['imports']['standard_library']
    third_party_deps = data['imports']['third_party']
    
    if local_deps or std_lib_deps or third_party_deps:
        content.append("- **Dependencies**: ")
        
        # Local dependencies
        if local_deps:
            content.append("  - **Local**:")
            for import_info in sorted(local_deps, key=lambda x: x['module']):
                formatted_import = format_import_details(import_info)
                change_indicator = ""
                if not dep_changes['unchanged']:
                    if import_info['module'] in dep_changes['added']:
                        change_indicator = " (üÜï)"
                    elif import_info['module'] in dep_changes['removed']:
                        change_indicator = " (‚ùå)"
                content.append(f"    - `{formatted_import}`{change_indicator}")
        
        # Standard library dependencies
        if std_lib_deps:
            content.append("  - **Standard Library**:")
            for import_info in sorted(std_lib_deps, key=lambda x: x['module']):
                formatted_import = format_import_details(import_info)
                content.append(f"    - `{formatted_import}`")
        
        # Third-party dependencies
        if third_party_deps:
            content.append("  - **Third-party**:")
            for import_info in sorted(third_party_deps, key=lambda x: x['module']):
                formatted_import = format_import_details(import_info)
                content.append(f"    - `{formatted_import}`")
    else:
        content.append("- **Dependencies**: None (no imports)")
    
    # Reverse dependencies (automated)
    if reverse_deps:
        content.append("- **Used by**: ")
        for user in reverse_deps:
            content.append(f"  - `{user}`")
    else:
        content.append("- **Used by**: None (not imported by other modules)")
    
    # Automated analysis summary
    if not dep_changes['unchanged']:
        content.append("")
        content.append("**Dependency Changes**:")
        if dep_changes['added']:
            content.append(f"- Added: {', '.join(dep_changes['added'])}")
        if dep_changes['removed']:
            content.append(f"- Removed: {', '.join(dep_changes['removed'])}")
    
    # Manual enhancement section marker (simplified)
    content.append("")
    content.append("<!-- MANUAL_ENHANCEMENT_START -->")
    content.append("<!-- Add any additional context, key functions, or special considerations here -->")
    content.append("<!-- MANUAL_ENHANCEMENT_END -->")
    
    return content

def preserve_manual_enhancements(existing_content: str, new_content: str) -> str:
    """Preserve manual enhancements from existing content when regenerating."""
    if not existing_content:
        return new_content
    
    # Extract general manual enhancement section from existing content
    general_manual_enhancement = ""
    start_marker = "## üîÑ **Circular Dependencies**"
    if start_marker in existing_content:
        # Find the start of the general manual enhancement section
        start_pos = existing_content.find(start_marker)
        # Find the end of the file
        end_pos = existing_content.find("<!-- MANUAL_ENHANCEMENT_END -->", start_pos)
        if end_pos != -1:
            end_pos += len("<!-- MANUAL_ENHANCEMENT_END -->")
            general_manual_enhancement = existing_content[start_pos:end_pos]
    
    # Split content into sections for module-specific enhancements
    sections = {}
    current_section = None
    current_content = []
    
    for line in existing_content.split('\n'):
        # Look for module headers in both formats:
        # 1. "#### `module_name.py`" (with #### prefix)
        # 2. "module_name.py" (without #### prefix)
        if (line.startswith('#### `') and line.endswith('`') and '.py`' in line):
            # Format: "#### `module_name.py`"
            if current_section:
                sections[current_section] = '\n'.join(current_content)
            
            current_section = line[6:-1]  # Remove "#### `" and "`"
            current_content = [line]
        elif (line.strip().endswith('.py') and 
              not line.startswith('-') and
              not line.startswith('**') and
              '/' in line):
            # Format: "module_name.py" (legacy format)
            if current_section:
                sections[current_section] = '\n'.join(current_content)
            
            current_section = line.strip()
            current_content = [line]
        elif current_section:
            current_content.append(line)
    
    if current_section:
        sections[current_section] = '\n'.join(current_content)
    
    # Extract manual enhancements
    manual_enhancements = {}
    for section_name, section_content in sections.items():
        start_marker = "<!-- MANUAL_ENHANCEMENT_START -->"
        end_marker = "<!-- MANUAL_ENHANCEMENT_END -->"
        
        start_pos = section_content.find(start_marker)
        end_pos = section_content.find(end_marker)
        
        if start_pos != -1 and end_pos != -1:
            # Extract the entire manual enhancement content including markers
            manual_content = section_content[start_pos:end_pos + len(end_marker)]
            # Preserve if it contains any content beyond the placeholder
            if "Add any additional context" not in manual_content or len(manual_content.strip()) > len("<!-- MANUAL_ENHANCEMENT_START -->\n<!-- MANUAL_ENHANCEMENT_END -->"):
                manual_enhancements[section_name] = manual_content
            else:
                pass # No manual enhancement content found
    
    # Apply manual enhancements to new content
    result_lines = []
    current_section = None
    in_manual_section = False
    skip_until_end = False
    
    for line in new_content.split('\n'):
        # Look for module headers in the format "#### `module_name.py`" (with #### prefix)
        if line.startswith('#### `') and line.endswith('`'):
            # Extract the module name from the #### format
            module_name = line[6:-1]  # Remove "#### `" and "`"
            current_section = module_name
            in_manual_section = False
            skip_until_end = False
            result_lines.append(line)
        elif line == "<!-- MANUAL_ENHANCEMENT_START -->":
            in_manual_section = True
            if current_section and current_section in manual_enhancements:
                # Insert preserved manual enhancement
                result_lines.append(manual_enhancements[current_section])
                skip_until_end = True  # Skip all content until we find the end marker
            else:
                # Keep the placeholder
                result_lines.append(line)
        elif line == "<!-- MANUAL_ENHANCEMENT_END -->":
            in_manual_section = False
            skip_until_end = False
            # Only add this line if we didn't insert preserved content
            if not (current_section and current_section in manual_enhancements):
                result_lines.append(line)
        elif in_manual_section and skip_until_end:
            # Skip all content between start and end when we have preserved content
            continue
        elif in_manual_section:
            # Keep placeholder content when we don't have preserved content
            result_lines.append(line)
        else:
            result_lines.append(line)
    
    # Add general manual enhancement section at the end if it exists
    if general_manual_enhancement:
        result_lines.append("")
        result_lines.append(general_manual_enhancement)
    
    return '\n'.join(result_lines)

def identify_modules_needing_enhancement(existing_content: str, actual_imports: Dict[str, Dict]) -> Dict[str, str]:
    """Identify modules that need manual enhancements or updates."""
    enhancement_status = {}
    
    # Parse existing manual enhancements
    existing_enhancements = {}
    if existing_content:
        sections = {}
        current_section = None
        current_content = []
        
        for line in existing_content.split('\n'):
            # Look for module headers in both formats:
            # 1. "#### `module_name.py`" (with #### prefix)
            # 2. "module_name.py" (without #### prefix)
            if (line.startswith('#### `') and line.endswith('`') and '.py`' in line):
                # Format: "#### `module_name.py`"
                if current_section:
                    sections[current_section] = '\n'.join(current_content)
                
                current_section = line[6:-1]  # Remove "#### `" and "`"
                current_content = [line]
            elif (line.strip().endswith('.py') and 
                  not line.startswith('-') and
                  not line.startswith('**') and
                  '/' in line):
                # Format: "module_name.py" (legacy format)
                if current_section:
                    sections[current_section] = '\n'.join(current_content)
                
                current_section = line.strip()
                current_content = [line]
            elif current_section:
                current_content.append(line)
        
        if current_section:
            sections[current_section] = '\n'.join(current_content)
        
        # Extract manual enhancements
        for section_name, section_content in sections.items():
            start_marker = "<!-- MANUAL_ENHANCEMENT_START -->"
            end_marker = "<!-- MANUAL_ENHANCEMENT_END -->"
            
            start_pos = section_content.find(start_marker)
            end_pos = section_content.find(end_marker)
            
            if start_pos != -1 and end_pos != -1:
                manual_content = section_content[start_pos:end_pos + len(end_marker)]
                # Check if it's just the placeholder
                if "Add any additional context" in manual_content and "Enhanced Purpose" not in manual_content:
                    existing_enhancements[section_name] = "placeholder"
                else:
                    existing_enhancements[section_name] = "enhanced"
            else:
                existing_enhancements[section_name] = "missing"
    
    # Analyze each module
    for file_path, data in actual_imports.items():
        section_name = file_path  # Use file_path directly as section name
        
        if section_name not in existing_enhancements:
            enhancement_status[file_path] = "new_module"
        elif existing_enhancements[section_name] == "placeholder":
            enhancement_status[file_path] = "needs_enhancement"
        elif existing_enhancements[section_name] == "enhanced":
            # Check if dependencies have changed significantly
            # For now, just mark as up_to_date since we're preserving manual enhancements
            # The dependency comparison logic needs to be fixed to compare the same type of dependencies
            enhancement_status[file_path] = "up_to_date"
        else:
            enhancement_status[file_path] = "missing_enhancement"
    
    return enhancement_status

def update_module_dependencies():
    """Update MODULE_DEPENDENCIES.md with hybrid approach."""
    print("[SCAN] Scanning all Python files for imports...")
    actual_imports = scan_all_python_files()
    
    # Read existing content to preserve manual enhancements
    registry_path = Path(__file__).parent.parent / 'MODULE_DEPENDENCIES.md'
    existing_content = ""
    if registry_path.exists():
        try:
            with open(registry_path, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        except Exception as e:
            print(f"[WARN] Could not read existing file: {e}")
    
    print("[GEN] Generating MODULE_DEPENDENCIES.md content...")
    new_content = generate_module_dependencies_content(actual_imports, existing_content)
    
    # Identify modules needing enhancement
    enhancement_status = identify_modules_needing_enhancement(existing_content, actual_imports)
    
    # Preserve manual enhancements
    final_content = preserve_manual_enhancements(existing_content, new_content)
    
    # Write the updated content
    try:
        with open(registry_path, 'w', encoding='utf-8') as f:
            f.write(final_content)
        
        print(f"[SUCCESS] MODULE_DEPENDENCIES.md updated successfully!")
        print(f"[STATS] Statistics:")
        print(f"   Files scanned: {len(actual_imports)}")
        print(f"   Total imports: {sum(data['total_imports'] for data in actual_imports.values())}")
        print(f"   Local dependencies: {sum(len(data['imports']['local']) for data in actual_imports.values())}")
        print(f"   Coverage: 100% (all files documented)")
        print(f"   File: {registry_path}")
        
        # Report enhancement status
        print(f"\n[ENHANCEMENT] Manual Enhancement Status:")
        status_counts = {}
        for status in enhancement_status.values():
            status_counts[status] = status_counts.get(status, 0) + 1
        
        for status, count in sorted(status_counts.items()):
            status_display = {
                'new_module': 'New modules (need enhancement)',
                'needs_enhancement': 'Modules with placeholder content',
                'dependencies_changed': 'Modules with changed dependencies',
                'up_to_date': 'Modules with current enhancements',
                'missing_enhancement': 'Modules missing enhancement markers'
            }.get(status, status)
            print(f"   {status_display}: {count}")
        
        # Show specific modules needing attention
        priority_modules = {k: v for k, v in enhancement_status.items() 
                          if v in ['new_module', 'needs_enhancement', 'dependencies_changed']}
        
        if priority_modules:
            print(f"\n[PRIORITY] Modules needing manual attention:")
            for file_path, status in sorted(priority_modules.items()):
                status_icon = {
                    'new_module': 'üÜï',
                    'needs_enhancement': 'üìù',
                    'dependencies_changed': 'üîÑ'
                }.get(status, '‚ùì')
                print(f"   {status_icon} {file_path} ({status})")
        
        return True
        
    except Exception as e:
        print(f"[ERROR] Failed to write MODULE_DEPENDENCIES.md: {e}")
        return False

if __name__ == "__main__":
    update_module_dependencies() 